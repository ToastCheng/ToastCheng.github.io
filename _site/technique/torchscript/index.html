<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.19.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Torchscript: train in Python, run in C++ - Toast</title>
<meta name="description" content="This article is mainly about serialize a pytorch model, and load it into C++. ">


  <meta name="author" content="ShihCheng Tu">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Toast">
<meta property="og:title" content="Torchscript: train in Python, run in C++">
<meta property="og:url" content="/technique/torchscript/">


  <meta property="og:description" content="This article is mainly about serialize a pytorch model, and load it into C++. ">







  <meta property="article:published_time" content="2020-01-09T13:32:56+08:00">





  

  


<link rel="canonical" href="/technique/torchscript/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "ShihCheng Tu",
      "url": "/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Toast Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Toast
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about">About</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">ShihCheng Tu</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>I am an <strong>amazing</strong> person.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Taipei, Taiwan</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
        
          
        
      

      

      
        <li>
          <a href="mailto:mrtoastcheng@gmail.com">
            <meta itemprop="email" content="mrtoastcheng@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Torchscript: train in Python, run in C++">
    <meta itemprop="description" content="This article is mainly about serialize a pytorch model, and load it into C++.">
    <meta itemprop="datePublished" content="2020-01-09T13:32:56+08:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Torchscript: train in Python, run in C++
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read

</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>This article is mainly about serialize a pytorch model, and load it into C++.</p>

<h3 id="first-of-all-traced-your-model"><strong>First of all, traced your model</strong></h3>

<p>“Trace” is a mechanism which pytorch used to record the behavior of neural nets. 
To perform tracing, first you have to initialize your model, say that you have trained your model until it reach production level.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">your.model.path</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="c1"># assume that Model() is simply a network class which inherit nn.Module.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>

<span class="c1"># of course you have to load the weight of your model.
</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">"{your-weight-path}"</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cpu"</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
</code></pre></div></div>

<p>Then you have to make an <code class="highlighter-rouge">example</code>, i.e., a tensor that match the size of <code class="highlighter-rouge">model</code>’s input size. Note that you will have to set <code class="highlighter-rouge">model</code> to <code class="highlighter-rouge">eval()</code> for disabling training features since we are doing this for inference.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<p>After configuration, just simply called <code class="highlighter-rouge">torch.jit.trace</code> and pass the model and example to it. Once the tracing is done successfully, you can saved it into file.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">check_trace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">traced</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">"traced_model.pt"</span><span class="p">)</span>
</code></pre></div></div>

<p>You can make a simple check to see if the output is the same as the original model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">"traced_model.pt"</span><span class="p">)</span>

<span class="n">model</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="c1"># output: 
# tensor([[-10.5246, -15.4433, -15.8299, -14.9295, -13.4168, -10.2231]],
#        grad_fn=&lt;AddmmBackward&gt;)
</span><span class="n">traced_model</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="c1"># output: 
# tensor([[-10.5246, -15.4433, -15.8299, -14.9295, -13.4168, -10.2231]],
#        grad_fn=&lt;AddmmBackward&gt;)
</span></code></pre></div></div>

<p><em>note 1</em>
The traced torchscript file does not seems to be platform-independent, if you trace it on Mac, and load it in Windows, unpredictable errors happens when loading model.</p>

<p><em>note 2</em>
As offical document stated, if your model contains control flows(<code class="highlighter-rouge">if</code>, <code class="highlighter-rouge">else</code>), or any operations that depends on the value of <code class="highlighter-rouge">example</code>, i.e., <code class="highlighter-rouge">example</code> cannot reach some parts in your model, the traced model will not perform the same as the original model. To tackle this, you will need to add <code class="highlighter-rouge">@torch.jit.script</code> in every function which contains control flow.</p>

<p>e.g.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_some_operation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="o">@</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
    <span class="k">def</span> <span class="nf">_some_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="o">...</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="o">...</span>
</code></pre></div></div>

<p><em>note 3</em>
If your model contains custom <code class="highlighter-rouge">autograd.Function</code>, the operation cannot be traced (yet). One solution is to write a C++ operation and build pytorch by yourself like <a href="http://lernapparat.de/pytorch-traceable-differentiable/">this</a>, or you can simply try to use existed operations to build your custom operation rather than inherit <code class="highlighter-rouge">autograd.Function</code>.</p>

<h3 id="second-write-c-inference-code"><strong>Second, write C++ inference code</strong></h3>

<p>Though the official document has made it pretty stright forward, I do have some hard time building it in Windows (no problem in unix-like). So I will focus on the steps that need to perform on Windows:</p>

<ol>
  <li>Download source:
    <ul>
      <li>cpu:
        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip
</code></pre></div>        </div>
      </li>
      <li>cuda 9.0:
        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> wget https://download.pytorch.org/libtorch/nightly/cu90/libtorch-shared-with-deps-latest.zip
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Preparing main.cpp, here I will extend the <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">official example code</a>. The first part below is how c++ load a traced model, simply call <code class="highlighter-rouge">torch::jit::load()</code>.</li>
</ol>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;torch/script.h&gt;
</span>
<span class="cp">#include &lt;iostream&gt;
#include &lt;string.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">model_path</span> <span class="o">=</span> <span class="s">"traced_model.pt"</span>

  <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span> <span class="n">module</span><span class="p">;</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="c1">// Deserialize the ScriptModule from a file using torch::jit::load().</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">catch</span> <span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">Error</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"error loading the model</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="p">...</span>
</code></pre></div></div>
<p>Say that you have an integer pointer (1-D array, flatten from a 2 or 3-D array) <code class="highlighter-rouge">int* data</code>, which is a way that C++ store image data. You can simply use <code class="highlighter-rouge">torch::from_blob()</code> to read the data into tensor, the sizes of it will be given in the second argument. The <code class="highlighter-rouge">options</code> is the way that <code class="highlighter-rouge">torch</code> used (as the third argument) to decide the type that will be read. You can find more in <a href="https://pytorch.org/cppdocs/notes/tensor_creation.html#configuring-properties-of-the-tensor">here</a>.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">...</span> <span class="p">(</span><span class="n">still</span> <span class="n">in</span> <span class="n">main</span><span class="p">())</span>
  
  <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">*</span> <span class="n">data</span> <span class="o">=</span> <span class="n">get_image_data</span><span class="p">();</span> <span class="c1">// some api that you get your data.</span>
  
  <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">t</span><span class="p">;</span>
  <span class="k">auto</span> <span class="n">options</span> <span class="o">=</span> <span class="n">c10</span><span class="o">::</span><span class="n">TensorOptions</span><span class="p">().</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kShort</span><span class="p">);</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">{</span> 
    <span class="cm">/*batch=*/</span><span class="mi">1</span><span class="p">,</span> 
    <span class="cm">/*channel=*/</span><span class="mi">1</span><span class="p">,</span> 
    <span class="cm">/*width=*/</span><span class="n">width</span><span class="p">,</span> 
    <span class="cm">/*height=*/</span><span class="n">height</span> 
  <span class="p">},</span> <span class="n">options</span><span class="p">);</span>
  
  <span class="p">...</span>
</code></pre></div></div>

<p>Lastly, you will have to initialize a vector of <code class="highlighter-rouge">torch::jit::IValue</code> as an input for a torchscript model. simply <code class="highlighter-rouge">push_back</code> a batch of tensor inside and you can run with <code class="highlighter-rouge">module.forward()</code>. You can get the result using <code class="highlighter-rouge">toTensor()</code>. There are some useful member functions of <code class="highlighter-rouge">Tensor</code>:</p>
<ul>
  <li>observe the shape by <code class="highlighter-rouge">sizes()</code></li>
  <li>cast the value into primitive type by <code class="highlighter-rouge">item&lt;type&gt;()</code></li>
</ul>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">...</span> <span class="p">(</span><span class="n">still</span> <span class="n">in</span> <span class="n">main</span><span class="p">())</span>
  
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span> <span class="n">input</span><span class="p">;</span>
  <span class="n">input</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input</span><span class="p">).</span><span class="n">toTensor</span><span class="p">();</span>
  
  <span class="c1">// say that we want to know the output of the first input(0), second dimension(1)</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"result: "</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  
  <span class="c1">// observe the shape</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="p">.</span><span class="n">sizes</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="err">}</span>
</code></pre></div></div>

<h3 id="finally-build-the-app"><strong>Finally, build the app</strong></h3>

<ol>
  <li>Preparing cmakefile
 We will have to write a CMakeLists to build the app. If you have not seen any <code class="highlighter-rouge">CMakeLists.txt</code> before it would be a little timidating, but it can be dissect:
    <ul>
      <li><code class="highlighter-rouge">project</code>
 The name of the app, usually the name of root directory.</li>
      <li><code class="highlighter-rouge">set</code> 
 Set any argument that is needed.</li>
      <li><code class="highlighter-rouge">find_package</code>
 Extremely handy if a third-party package has cmake support. cmake will find files like <code class="highlighter-rouge">{uppercase package name}Config.cmake</code> or <code class="highlighter-rouge">{lowercase package name}-config.cmake</code>. And You will not need to configure any lib path, include path by yourself. But you need to set <code class="highlighter-rouge">CMAKE_PREFIX_PATH</code> let cmake to know where to find those files. If you have multiple package you can set it like:  <code class="highlighter-rouge">CMAKE_PREFIX_PATH={path 1}:{path 2}</code></li>
      <li><code class="highlighter-rouge">add_executable</code>
 Like <code class="highlighter-rouge">g++ -o test-torch main.cpp</code>.</li>
      <li>The <code class="highlighter-rouge">MSVC</code> part
 For Windows OS only, provided by document.</li>
    </ul>
  </li>
</ol>

<div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cmake_minimum_required</span><span class="p">(</span>VERSION 3.0 FATAL_ERROR<span class="p">)</span>
<span class="nb">project</span><span class="p">(</span>test-torch<span class="p">)</span>

<span class="c1"># if not set here, you should set it in argument with -D flag. e.g. -DCMAKE_PREFIX_PATH={libtorch path}</span>
<span class="nb">set</span><span class="p">(</span>CMAKE_PREFIX_PATH <span class="s2">"{libtorch path}"</span><span class="p">)</span>
<span class="c1"># if not set, annoying warnings will pop up</span>
<span class="nb">cmake_policy</span><span class="p">(</span>SET CMP0054 NEW<span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span>Torch REQUIRED<span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span>test-torch main.cpp<span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>test-torch <span class="s2">"</span><span class="si">${</span><span class="nv">TORCH_LIBRARIES</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">set_property</span><span class="p">(</span>TARGET test-torch PROPERTY CXX_STANDARD 14<span class="p">)</span>

<span class="nb">if</span> <span class="p">(</span>MSVC<span class="p">)</span>
  <span class="nb">file</span><span class="p">(</span>GLOB TORCH_DLLS <span class="s2">"</span><span class="si">${</span><span class="nv">TORCH_INSTALL_PREFIX</span><span class="si">}</span><span class="s2">/lib/*.dll"</span><span class="p">)</span>
  <span class="nb">add_custom_command</span><span class="p">(</span>TARGET test-torch
                     POST_BUILD
                     COMMAND <span class="si">${</span><span class="nv">CMAKE_COMMAND</span><span class="si">}</span> -E copy_if_different
                     <span class="si">${</span><span class="nv">TORCH_DLLS</span><span class="si">}</span>
                     $&lt;TARGET_FILE_DIR:test-torch&gt;<span class="p">)</span>
<span class="nb">endif</span> <span class="p">(</span>MSVC<span class="p">)</span>
</code></pre></div></div>

<ol>
  <li>Build</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>build
<span class="nb">cd </span>build
<span class="c"># set CMAKE_PREFIX_PATH to let cmake knows where to find the cmake file of libtorch.</span>
cmake <span class="nt">-DCMAKE_PREFIX_PATH</span><span class="o">=</span><span class="s2">"{libtorch path}"</span> ..
<span class="c"># OR if you set inside CMakeLists.txt you can alternatively run:</span>
cmake ..

<span class="c"># build, equivalent to "make"</span>
cmake <span class="nt">--build</span> <span class="nb">.</span> <span class="nt">--config</span> Release

<span class="c"># after building, dlls will be generated at the project root, </span>
<span class="c"># copy them to the path in where the executable is.</span>
<span class="nb">cp </span>c:<span class="se">\.</span>..<span class="se">\t</span>est-torch<span class="se">\*</span>.dll C:<span class="se">\.</span>..<span class="se">\t</span>est-torch<span class="se">\b</span>uild<span class="se">\R</span>elease<span class="se">\</span>
<span class="nb">cd </span>Release

<span class="c"># run!</span>
.<span class="se">\t</span>est-torch.exe
</code></pre></div></div>

<p>reference</p>
<ul>
  <li><a href="https://discuss.pytorch.org/t/error-running-libtorch-example-program/53980/6">build libtorch with cmake</a></li>
  <li><a href="http://lernapparat.de/pytorch-traceable-differentiable/">custom op</a></li>
  <li><a href="https://pytorch.org/tutorials/advanced/cpp_export.html">official c++ tutorial</a></li>
  <li><a href="https://pytorch.org/cppdocs/notes/tensor_creation.html#configuring-properties-of-the-tensor">tensorOption</a></li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#c" class="page__taxonomy-item" rel="tag">c++</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#pytorch" class="page__taxonomy-item" rel="tag">pytorch</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#torchscript" class="page__taxonomy-item" rel="tag">torchscript</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#technique" class="page__taxonomy-item" rel="tag">technique</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-01-09T13:32:56+08:00">January 9, 2020</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Torchscript%3A+train+in+Python%2C+run+in+C%2B%2B%20%2Ftechnique%2Ftorchscript%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=%2Ftechnique%2Ftorchscript%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=%2Ftechnique%2Ftorchscript%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/technique/envoy/" class="pagination--pager" title="Integrate envoy &amp; grpc-web in k8s
">Previous</a>
    
    
      <a href="/technique/set-up-your-pacs-server-in-no-time/" class="pagination--pager" title="Orthanc: setup your PACS server in no time
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/technique/set-up-your-pacs-server-in-no-time/" rel="permalink">Orthanc: setup your PACS server in no time
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  2 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">This article demonstrate how you can setup a PACS server using docker.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/technique/envoy/" rel="permalink">Integrate envoy &amp; grpc-web in k8s
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  3 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Envoy is a proxy for modern web app. More importantly, it has a first class support for gRPC.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 ShihCheng Tu. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>










  </body>
</html>
