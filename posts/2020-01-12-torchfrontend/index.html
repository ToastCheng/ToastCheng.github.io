<!doctype html><html lang=en-us><head><title>Torchscript: Torch Frontend Note |
ShihCheng Tu</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=description content="Torch C++ Frontend Note First of all, include libtorch by"><meta property="og:title" content="Torchscript: Torch frontend note"><meta property="og:description" content="Torch C++ Frontend Note First of all, include libtorch by"><meta property="og:type" content="article"><meta property="og:url" content="https://toastcheng.github.io/posts/2020-01-12-torchfrontend/"><meta property="article:published_time" content="2020-01-12T22:03:34+08:00"><meta property="article:modified_time" content="2020-01-12T22:03:34+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Torchscript: Torch frontend note"><meta name=twitter:description content="Torch C++ Frontend Note First of all, include libtorch by"><meta itemprop=name content="Torchscript: Torch frontend note"><meta itemprop=description content="Torch C++ Frontend Note First of all, include libtorch by"><meta itemprop=datePublished content="2020-01-12T22:03:34+08:00"><meta itemprop=dateModified content="2020-01-12T22:03:34+08:00"><meta itemprop=wordCount content="271"><meta itemprop=keywords content="note,pytorch,c++,machine learning,"><link rel=canonical href=https://toastcheng.github.io/posts/2020-01-12-torchfrontend/><link rel=icon type=image/png href=https://toastcheng.github.ioimage/favicon.ico><link rel=stylesheet href=/css/font-awesome.min.css><link rel=stylesheet href=/css/bulma.min.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-168042428-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script src=/js/ramium.js></script><link rel=stylesheet href=/css/ramium.css></head><body><nav class="navbar is-dark" role=navigation aria-label="main navigation"><div class=navbar-brand><a class=navbar-item href=/><strong>ShihCheng Tu</strong></a>
<a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarBasicExample><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></a></div><div id=navbarBasicExample class=navbar-menu><div class=navbar-start><a class=navbar-item href=/>Home</a><div class="navbar-item has-dropdown is-hoverable"><a class=navbar-link>This Blog</a><div class=navbar-dropdown><a class=navbar-item href=/tags/>All Tags</a>
<a class=navbar-item href=/sections/>All Sections</a>
<a class=navbar-item href=/posts/>All Posts</a></div></div><a class=navbar-item href=/author/>Author</a></div><div class=navbar-end><a class="navbar-item navgithub" href=https://github.com/toastcheng/ target=_blank><i class="fa fa-github fa-2x"></i></a><div class=navbar-item><form id=cse-search-box-form-id onsubmit="return executeQuery();" role=search><div class="field has-addons"><div class="control is-expanded"><input id=cse-search-input-box-id size=15 class=input type=text autocomplete=off placeholder="&#xf1a0; Google search" style=font-family:Arial,FontAwesome></div><div class=control><button type=submit class="button is-black">
<i class="fa fa-search"></i></a></button></div></div></form></div></div></div></nav><div class="columns is-centered"><div id=page-body class="column is-7"><div class="content blog"><h1>Torchscript: Torch Frontend Note</h1><div id=infobar class="level is-mobile"><div class=level-left><div class=level-item><p class="subtitle info date">Jan 12, 2020</p></div><div class=level-item><p class="subtitle info">2 mins read</p></div></div><div class="level-right is-hidden-touch"><div class=tags><a class="tag is-dark is-rounded" href=/tags/note>Note</a>
<a class="tag is-dark is-rounded" href=/tags/pytorch>Pytorch</a>
<a class="tag is-dark is-rounded" href=/tags/c++>C++</a>
<a class="tag is-dark is-rounded" href=/tags/machine-learning>Machine Learning</a></div></div></div><div class="tags is-hidden-desktop"><a class="tag is-dark is-rounded" href=/tags/note>Note</a>
<a class="tag is-dark is-rounded" href=/tags/pytorch>Pytorch</a>
<a class="tag is-dark is-rounded" href=/tags/c++>C++</a>
<a class="tag is-dark is-rounded" href=/tags/machine-learning>Machine learning</a></div><div class=blog-text><h1 id=torch-c-frontend-note>Torch C++ Frontend Note</h1><p>First of all, include <code>libtorch</code> by</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;torch/script.h&gt;</span><span style=color:#75715e>
</span></code></pre></div><h3 id=frequently-used-operations>Frequently used operations</h3><ul><li>Check if cuda is available</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>torch<span style=color:#f92672>::</span>Device device(torch<span style=color:#f92672>::</span>cuda<span style=color:#f92672>::</span>is_available() <span style=color:#f92672>?</span> torch<span style=color:#f92672>::</span>kCUDA : torch<span style=color:#f92672>::</span>kCPU);
</code></pre></div><ul><li>Specific device (by id)</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#75715e>// device 0
</span><span style=color:#75715e></span>torch<span style=color:#f92672>::</span>Device device(torch<span style=color:#f92672>::</span>kCUDA, <span style=color:#ae81ff>0</span>);
</code></pre></div><ul><li>Convert a image with (1D-pointer type) into tensor</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#66d9ef>int</span> width <span style=color:#f92672>=</span> <span style=color:#ae81ff>512</span>;
<span style=color:#66d9ef>int</span> height <span style=color:#f92672>=</span> <span style=color:#ae81ff>512</span>;
<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> pixelData <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>) malloc(width <span style=color:#f92672>*</span> height <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
some_initialization(pixelData); <span style=color:#75715e>// do something to load the data.
</span><span style=color:#75715e></span>at<span style=color:#f92672>::</span>Tensor t <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>from_blob(pixelData, { width, height });
</code></pre></div><ul><li>Convert with options</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#66d9ef>auto</span> options <span style=color:#f92672>=</span> c10<span style=color:#f92672>::</span>TensorOptions().dtype(torch<span style=color:#f92672>::</span>kShort);
at<span style=color:#f92672>::</span>Tensor t <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>from_blob(pixelData, { <span style=color:#ae81ff>1</span>, width, height }, options);
</code></pre></div><ul><li>Type casting</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>tensor <span style=color:#f92672>=</span> tensor.toType(torch<span style=color:#f92672>::</span>kFloat32);
</code></pre></div><ul><li>Convert tensor data into primitive types</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#75715e>// get the value of tensor on index(0, 0) to float
</span><span style=color:#75715e></span><span style=color:#66d9ef>float</span> val <span style=color:#f92672>=</span> tensor[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>].item<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>()
</code></pre></div><h3 id=compilation>Compilation</h3><ul><li>CUDA</li></ul><ol><li>CUDA Toolkit
Directly install by official installer. Once the installation is completed, the <code>CUDA_TOOLKIT_ROOT_DIR</code> will be automatically set.</li><li>cuDNN
Download from official website. Set the include path <code>CUDNN_LIBRARY_PATH</code> and library path <code>CUDNN_INCLUDE_PATH</code> in <code>CMakeLists.txt</code> to where you store the cuDNN package.</li></ol><h3 id=torchscript>Torchscript</h3><h3 id=custom-dataset-and-dataloader>Custom Dataset and DataLoader</h3><p>Dataset</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CustomDataset</span> <span style=color:#f92672>:</span> <span style=color:#66d9ef>public</span> torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>Dataset<span style=color:#f92672>&lt;</span>CustomDataset<span style=color:#f92672>&gt;</span> {
  <span style=color:#75715e>// use Batch as a alias of torch::data::Example&lt;&gt;
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>using</span> Batch <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>Example<span style=color:#f92672>&lt;&gt;</span>;
  <span style=color:#66d9ef>private</span><span style=color:#f92672>:</span>
    std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>std<span style=color:#f92672>::</span>string<span style=color:#f92672>&gt;</span> file_list;

  <span style=color:#66d9ef>public</span><span style=color:#f92672>:</span>
    <span style=color:#66d9ef>explicit</span> ICHDataset(<span style=color:#66d9ef>const</span> std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>std<span style=color:#f92672>::</span>string<span style=color:#f92672>&gt;</span> file_list) 
      <span style=color:#f92672>:</span> file_list(file_list) {}

    Batch <span style=color:#a6e22e>get</span>(size_t index) {

      <span style=color:#66d9ef>auto</span>  <span style=color:#f92672>=</span> parse_data(index);

      <span style=color:#66d9ef>return</span> { data, label };
    } 

    torch<span style=color:#f92672>::</span>optional<span style=color:#f92672>&lt;</span>size_t<span style=color:#f92672>&gt;</span> size() <span style=color:#66d9ef>const</span> {
      <span style=color:#66d9ef>return</span> file_list.size();
    }
};
</code></pre></div><p>DataLoader</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#66d9ef>auto</span> dataset <span style=color:#f92672>=</span> ICHDataset(file_list).map(torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>transforms<span style=color:#f92672>::</span>Stack<span style=color:#f92672>&lt;&gt;</span>());;;
<span style=color:#66d9ef>auto</span> dataloader <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>make_data_loader(
  std<span style=color:#f92672>::</span>move(dataset),
  torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>DataLoaderOptions()
    .batch_size(batch_size)
    .workers(<span style=color:#ae81ff>2</span>)
    .enforce_ordering(true)
  );
</code></pre></div><h3 id=errors-pitfalls>Errors, pitfalls</h3><pre><code>error: ‘is_available’ is not a member of ‘at::cuda’
  if (torch::cuda::is_available())` 
</code></pre><ul><li><p>Include <code>&lt;torch/torch.h></code>, though <code>&lt;torch.script.h></code> might works in the main.cpp file, it does not work in other files.
<a href=https://discuss.pytorch.org/t/torch-is-available-is-throwing-compilation-error/41158/3>https://discuss.pytorch.org/t/torch-is-available-is-throwing-compilation-error/41158/3</a></p></li><li><p>Compile CUDA version without CUDA-capable device
<a href=https://stackoverflow.com/questions/20186848/can-i-compile-a-cuda-program-without-having-a-cuda-device/20196425>https://stackoverflow.com/questions/20186848/can-i-compile-a-cuda-program-without-having-a-cuda-device/20196425</a></p></li></ul></div></div><div id=social-media-share class=has-text-centered><p><i>Sharing is caring!</i></p><br><div class=share-buttons><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" onclick="socialMediaPopUp(this.href,'',500,500);return false;" title="Share on Facebook. Opens in a new window."><img src=/img/icons/45px/facebook.png></a>
<a href="https://twitter.com/intent/tweet?text=Torchscript%3a%20Torch%20frontend%20note&url=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" onclick="socialMediaPopUp(this.href,'',500,500);return false;" title="Share on Twitter. Opens in a new window."><img src=/img/icons/45px/twitter.png></a>
<a href="http://www.reddit.com/submit?url=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" onclick="socialMediaPopUp(this.href,'',900,500);return false;" title="Share on Reddit. Opens in a new window."><img src=/img/icons/45px/reddit.png></a>
<a href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" onclick="socialMediaPopUp(this.href,'',900,500);return false;" title="Share on Pinterest. Opens in a new window."><img src=/img/icons/45px/pinterest.png></a>
<a href="http://www.tumblr.com/share/link?url=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" onclick="socialMediaPopUp(this.href,'',900,500);return false;" title="Share on Tumblr. Opens in a new window."><img src=/img/icons/45px/tumblr.png></a>
<a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f
			&title=Torchscript%3a%20Torch%20frontend%20note&summary=Torch%20C%2b%2b%20Frontend%20Note%20First%20of%20all%2c%20include%20libtorch%20by&source=rafed123.github.io" onclick="socialMediaPopUp(this.href,'',900,500);return false;" title="Share on LinkedIn. Opens in a new window."><img src=/img/icons/45px/linkedin.png></a>
<a href="mailto:?subject=Torchscript%3a%20Torch%20frontend%20note&body=Check out this site https%3a%2f%2ftoastcheng.github.io%2fposts%2f2020-01-12-torchfrontend%2f" title="Share via Email. Opens in a new window."><img src=/img/icons/45px/mail.png></a></div></div><br><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement('script');dsq.type='text/javascript';dsq.async=true;var disqus_shortname='toastcheng';dsq.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div><script async src="https://cse.google.com/cse.js?cx=Engineering%20blog"></script><gcse:searchresults-only></gcse:searchresults-only><footer class="footer has-background-dark"><div class="content has-text-centered has-text-white"><p>© 2020 Ramium. Powered by
<a class=has-text-light href=https://github.com/gohugoio/hugo target=_blank>Hugo</a>. Theme
<a class=has-text-light href=https://github.com/rafed123/ramium/ target=_blank>Ramium.</a></p></div></footer></body></html>